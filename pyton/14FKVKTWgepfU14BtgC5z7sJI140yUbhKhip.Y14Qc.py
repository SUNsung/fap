
        
          Returns:
    Object of same size as frequencies_hertz containing corresponding values
    on the mel scale.
  '''
  return _MEL_HIGH_FREQUENCY_Q * np.log(
      1.0 + (frequencies_hertz / _MEL_BREAK_FREQUENCY_HERTZ))
    
    
def build_labeled_sequence(seq, class_label, label_gain=False):
  '''Builds labeled sequence from input sequence.
    
      Returns:
    A dict of tensors (see return value of batch_parse_tf_example)
  '''
  shuffle_buffer_size = params.shuffle_buffer_size
  dataset = read_tf_records(
      shuffle_buffer_size, batch_size, tf_records, num_repeats=num_repeats,
      shuffle_records=shuffle_records, shuffle_examples=shuffle_examples,
      filter_amount=filter_amount)
  dataset = dataset.filter(lambda t: tf.equal(tf.shape(t)[0], batch_size))
  def batch_parse_tf_example(batch_size, dataset):
    return _batch_parse_tf_example(params.board_size, batch_size, dataset)
  dataset = dataset.map(functools.partial(
      batch_parse_tf_example, batch_size))
  return dataset.make_one_shot_iterator().get_next()
    
      def setUp(self):
    np.random.seed(1)
    self.feat = np.random.random(
        [utils_test.BOARD_SIZE, utils_test.BOARD_SIZE, 3])
    self.pi = np.random.random([utils_test.BOARD_SIZE ** 2 + 1])
    super().setUp()
    
        # Fetch the data
    (train_x, train_y), (test_x, test_y) = iris_data.load_data()
    
    
class RemoveDuplicateUrls(MRJob):
    
        def __init__(self):
        self.lookup = {}  # key: person_id, value: person_server
    
        def steps(self):
        '''Run the map and reduce steps.'''
        return [
            self.mr(mapper=self.mapper,
                    reducer=self.reducer)
        ]
    
        def extract_url(self, line):
        '''Extract the generated url from the log line.'''
        pass
    
        def __init__(self, num_levels):
        self.num_levels = num_levels
        self.levels = []  # List of Levels
    
        def message_group(self, group_id, message):
        pass
    
    
class DefaultCategories(Enum):
    
            # Convert integers to unsigned little-endian byte arrays.
        tests4 = {
            b'': 0,
            b'\x00': 0,
            b'\x01': 1,
            b'\x7f': 127,
            b'\x80': 128,
            b'\xff': 255,
            b'\x00\x01': 256,
            b'\xff\x7f': 32767,
            b'\x00\x80': 32768,
            b'\xff\xff': 65535,
            b'\x00\x00\x01': 65536,
        }
        check(tests4, 'little', signed=False)
    
    NUMBER_RE = re.compile(
    r'(-?(?:0|[1-9]\d*))(\.\d+)?([eE][-+]?\d+)?',
    (re.VERBOSE | re.MULTILINE | re.DOTALL))
    
        s.quit()

    
    #  This file is automatically generated; please don't muck it up!
#
#  To update the symbols in this file, 'cd' to the top directory of
#  the python source tree after building the interpreter and run:
#
#    ./python Lib/token.py
    
        def __init__(self):
        # setup variables used for HTML documentation
        self.server_name = 'XML-RPC Server Documentation'
        self.server_documentation = \
            'This server exports the following methods through the XML-RPC '\
            'protocol.'
        self.server_title = 'XML-RPC Server Documentation'
    
        def test_infile_stdout(self):
        infile = self._create_infile()
        rc, out, err = assert_python_ok('-m', 'json.tool', infile)
        self.assertEqual(rc, 0)
        self.assertEqual(out.splitlines(), self.expect.encode().splitlines())
        self.assertEqual(err, b'')
    
            self.assertEqual(x[:], a.tolist()[1:])
        with self.assertRaises(ValueError):
            c_int.from_buffer(a, -1)
        with self.assertRaises(ValueError):
            (c_int * 16).from_buffer(a, sizeof(c_int))
        with self.assertRaises(ValueError):
            (c_int * 1).from_buffer(a, 16 * sizeof(c_int))
    
            pt = pointer(Table(1, 2, 3))